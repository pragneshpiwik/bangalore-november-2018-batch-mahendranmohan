{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WH1Pr4KQlCh"
   },
   "source": [
    "### Build a DNN using Keras with `RELU` and `ADAM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbvI8LqlQlCl",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPW-a-qYQlCp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# fix random seed for reproducibility\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74cQBsi5QlCw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Collect Fashion mnist data from tf.keras.datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVWy0oDTr2Kj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainX, trainY),(testX, testY) = tf.keras.datasets.mnist.load_data()\n",
    "type(trainX)\n",
    "type(trainY)\n",
    "type(testX)\n",
    "type(testY)\n",
    "trainX.shape\n",
    "trainY.shape\n",
    "testX.shape\n",
    "testY.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no7aWYZyQlC1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Change train and test labels into one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UX6otc4wQlC2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)\n",
    "trainY.shape\n",
    "testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjNrRTdoQlC5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDJ9DHVNQlC7"
   },
   "source": [
    "#### Initialize model, reshape & normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "pCDQs_g1QlC8",
    "outputId": "e854b4d2-903a-4515-c21b-bd6a6e4fe2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBGwTTilQlDD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "IXbfpfOzQlDF",
    "outputId": "f46a2e3a-2634-4e9e-88bd-57bb8de1ff0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Hidden layers\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "#Dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5I8f5otcQlDJ"
   },
   "source": [
    "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2654 - acc: 0.9186 - val_loss: 0.1469 - val_acc: 0.9642\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1307 - acc: 0.9600 - val_loss: 0.1463 - val_acc: 0.9665\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0988 - acc: 0.9688 - val_loss: 0.1478 - val_acc: 0.9687\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0836 - acc: 0.9742 - val_loss: 0.1490 - val_acc: 0.9676\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0705 - acc: 0.9780 - val_loss: 0.1673 - val_acc: 0.9699\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0626 - acc: 0.9797 - val_loss: 0.1597 - val_acc: 0.9714\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0567 - acc: 0.9822 - val_loss: 0.1592 - val_acc: 0.9722\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0491 - acc: 0.9841 - val_loss: 0.1515 - val_acc: 0.9754\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0474 - acc: 0.9850 - val_loss: 0.1788 - val_acc: 0.9735\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0436 - acc: 0.9859 - val_loss: 0.1651 - val_acc: 0.9735\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0415 - acc: 0.9869 - val_loss: 0.1601 - val_acc: 0.9736\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0419 - acc: 0.9869 - val_loss: 0.1669 - val_acc: 0.9722\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0359 - acc: 0.9890 - val_loss: 0.1739 - val_acc: 0.9733\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0366 - acc: 0.9886 - val_loss: 0.1909 - val_acc: 0.9714\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0331 - acc: 0.9898 - val_loss: 0.1944 - val_acc: 0.9737\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0305 - acc: 0.9906 - val_loss: 0.1732 - val_acc: 0.9744\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0350 - acc: 0.9894 - val_loss: 0.2181 - val_acc: 0.9703\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0277 - acc: 0.9910 - val_loss: 0.2006 - val_acc: 0.9728\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0321 - acc: 0.9900 - val_loss: 0.2135 - val_acc: 0.9725\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0279 - acc: 0.9916 - val_loss: 0.1981 - val_acc: 0.9723\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0269 - acc: 0.9911 - val_loss: 0.1999 - val_acc: 0.9725\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0250 - acc: 0.9928 - val_loss: 0.2215 - val_acc: 0.9711\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0280 - acc: 0.9919 - val_loss: 0.2216 - val_acc: 0.9702\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0274 - acc: 0.9922 - val_loss: 0.2114 - val_acc: 0.9718\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0232 - acc: 0.9927 - val_loss: 0.2157 - val_acc: 0.9725\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0269 - acc: 0.9920 - val_loss: 0.1874 - val_acc: 0.9741\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0246 - acc: 0.9924 - val_loss: 0.2034 - val_acc: 0.9726\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0244 - acc: 0.9931 - val_loss: 0.2277 - val_acc: 0.9701\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0234 - acc: 0.9929 - val_loss: 0.2249 - val_acc: 0.9716\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0225 - acc: 0.9936 - val_loss: 0.2126 - val_acc: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1529de74400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(trainX,trainY, validation_data=(testX,testY), epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.2126 - acc: 0.9730\n",
      "[0.21263022537882206, 0.973]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(testX,testY)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "updated_R7_ExternalLab_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
