{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from sklearn.metrics import roc_curve , auc\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    " \n",
    "#tf.enable_eager_execution()\n",
    "tf.set_random_seed(42)\n",
    "#warnings.filterwarnings('ignore')\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "tf.executing_eagerly() \n",
    "tf.__version__\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the dataset\n",
    "df = pd.read_csv('../dataset/bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       RowNumber  CustomerId         Surname  CreditScore Geography  Gender  \\\n",
       "0             1    15634602        Hargrave          619    France  Female   \n",
       "1             2    15647311            Hill          608     Spain  Female   \n",
       "2             3    15619304            Onio          502    France  Female   \n",
       "3             4    15701354            Boni          699    France  Female   \n",
       "4             5    15737888        Mitchell          850     Spain  Female   \n",
       "5             6    15574012             Chu          645     Spain    Male   \n",
       "6             7    15592531        Bartlett          822    France    Male   \n",
       "7             8    15656148          Obinna          376   Germany  Female   \n",
       "8             9    15792365              He          501    France    Male   \n",
       "9            10    15592389              H?          684    France    Male   \n",
       "10           11    15767821          Bearce          528    France    Male   \n",
       "11           12    15737173         Andrews          497     Spain    Male   \n",
       "12           13    15632264             Kay          476    France  Female   \n",
       "13           14    15691483            Chin          549    France  Female   \n",
       "14           15    15600882           Scott          635     Spain  Female   \n",
       "15           16    15643966         Goforth          616   Germany    Male   \n",
       "16           17    15737452           Romeo          653   Germany    Male   \n",
       "17           18    15788218       Henderson          549     Spain  Female   \n",
       "18           19    15661507         Muldrow          587     Spain    Male   \n",
       "19           20    15568982             Hao          726    France  Female   \n",
       "20           21    15577657        McDonald          732    France    Male   \n",
       "21           22    15597945        Dellucci          636     Spain  Female   \n",
       "22           23    15699309       Gerasimov          510     Spain  Female   \n",
       "23           24    15725737          Mosman          669    France    Male   \n",
       "24           25    15625047             Yen          846    France  Female   \n",
       "25           26    15738191         Maclean          577    France    Male   \n",
       "26           27    15736816           Young          756   Germany    Male   \n",
       "27           28    15700772         Nebechi          571    France    Male   \n",
       "28           29    15728693      McWilliams          574   Germany  Female   \n",
       "29           30    15656300        Lucciano          411    France    Male   \n",
       "...         ...         ...             ...          ...       ...     ...   \n",
       "9970       9971    15587133        Thompson          518    France    Male   \n",
       "9971       9972    15721377            Chou          833    France  Female   \n",
       "9972       9973    15747927           Ch'in          758    France    Male   \n",
       "9973       9974    15806455          Miller          611    France    Male   \n",
       "9974       9975    15695474          Barker          583    France    Male   \n",
       "9975       9976    15666295           Smith          610   Germany    Male   \n",
       "9976       9977    15656062         Azikiwe          637    France  Female   \n",
       "9977       9978    15579969         Mancini          683    France  Female   \n",
       "9978       9979    15703563           P'eng          774    France    Male   \n",
       "9979       9980    15692664          Diribe          677    France  Female   \n",
       "9980       9981    15719276            T'ao          741     Spain    Male   \n",
       "9981       9982    15672754        Burbidge          498   Germany    Male   \n",
       "9982       9983    15768163         Griffin          655   Germany  Female   \n",
       "9983       9984    15656710           Cocci          613    France    Male   \n",
       "9984       9985    15696175  Echezonachukwu          602   Germany    Male   \n",
       "9985       9986    15586914          Nepean          659    France    Male   \n",
       "9986       9987    15581736        Bartlett          673   Germany    Male   \n",
       "9987       9988    15588839         Mancini          606     Spain    Male   \n",
       "9988       9989    15589329         Pirozzi          775    France    Male   \n",
       "9989       9990    15605622        McMillan          841     Spain    Male   \n",
       "9990       9991    15798964      Nkemakonam          714   Germany    Male   \n",
       "9991       9992    15769959     Ajuluchukwu          597    France  Female   \n",
       "9992       9993    15657105     Chukwualuka          726     Spain    Male   \n",
       "9993       9994    15569266          Rahman          644    France    Male   \n",
       "9994       9995    15719294            Wood          800    France  Female   \n",
       "9995       9996    15606229        Obijiaku          771    France    Male   \n",
       "9996       9997    15569892       Johnstone          516    France    Male   \n",
       "9997       9998    15584532             Liu          709    France  Female   \n",
       "9998       9999    15682355       Sabbatini          772   Germany    Male   \n",
       "9999      10000    15628319          Walker          792    France  Female   \n",
       "\n",
       "      Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0      42       2       0.00              1          1               1   \n",
       "1      41       1   83807.86              1          0               1   \n",
       "2      42       8  159660.80              3          1               0   \n",
       "3      39       1       0.00              2          0               0   \n",
       "4      43       2  125510.82              1          1               1   \n",
       "5      44       8  113755.78              2          1               0   \n",
       "6      50       7       0.00              2          1               1   \n",
       "7      29       4  115046.74              4          1               0   \n",
       "8      44       4  142051.07              2          0               1   \n",
       "9      27       2  134603.88              1          1               1   \n",
       "10     31       6  102016.72              2          0               0   \n",
       "11     24       3       0.00              2          1               0   \n",
       "12     34      10       0.00              2          1               0   \n",
       "13     25       5       0.00              2          0               0   \n",
       "14     35       7       0.00              2          1               1   \n",
       "15     45       3  143129.41              2          0               1   \n",
       "16     58       1  132602.88              1          1               0   \n",
       "17     24       9       0.00              2          1               1   \n",
       "18     45       6       0.00              1          0               0   \n",
       "19     24       6       0.00              2          1               1   \n",
       "20     41       8       0.00              2          1               1   \n",
       "21     32       8       0.00              2          1               0   \n",
       "22     38       4       0.00              1          1               0   \n",
       "23     46       3       0.00              2          0               1   \n",
       "24     38       5       0.00              1          1               1   \n",
       "25     25       3       0.00              2          0               1   \n",
       "26     36       2  136815.64              1          1               1   \n",
       "27     44       9       0.00              2          0               0   \n",
       "28     43       3  141349.43              1          1               1   \n",
       "29     29       0   59697.17              2          1               1   \n",
       "...   ...     ...        ...            ...        ...             ...   \n",
       "9970   42       7  151027.05              2          1               0   \n",
       "9971   34       3  144751.81              1          0               0   \n",
       "9972   26       4  155739.76              1          1               0   \n",
       "9973   27       7       0.00              2          1               1   \n",
       "9974   33       7  122531.86              1          1               0   \n",
       "9975   50       1  113957.01              2          1               0   \n",
       "9976   33       7  103377.81              1          1               0   \n",
       "9977   32       9       0.00              2          1               1   \n",
       "9978   40       9   93017.47              2          1               0   \n",
       "9979   58       1   90022.85              1          0               1   \n",
       "9980   35       6   74371.49              1          0               0   \n",
       "9981   42       3  152039.70              1          1               1   \n",
       "9982   46       7  137145.12              1          1               0   \n",
       "9983   40       4       0.00              1          0               0   \n",
       "9984   35       7   90602.42              2          1               1   \n",
       "9985   36       6  123841.49              2          1               0   \n",
       "9986   47       1  183579.54              2          0               1   \n",
       "9987   30       8  180307.73              2          1               1   \n",
       "9988   30       4       0.00              2          1               0   \n",
       "9989   28       4       0.00              2          1               1   \n",
       "9990   33       3   35016.60              1          1               0   \n",
       "9991   53       4   88381.21              1          1               0   \n",
       "9992   36       2       0.00              1          1               0   \n",
       "9993   28       7  155060.41              1          1               0   \n",
       "9994   29       2       0.00              2          0               0   \n",
       "9995   39       5       0.00              2          1               0   \n",
       "9996   35      10   57369.61              1          1               1   \n",
       "9997   36       7       0.00              1          0               1   \n",
       "9998   42       3   75075.31              2          1               0   \n",
       "9999   28       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "5           149756.71       1  \n",
       "6            10062.80       0  \n",
       "7           119346.88       1  \n",
       "8            74940.50       0  \n",
       "9            71725.73       0  \n",
       "10           80181.12       0  \n",
       "11           76390.01       0  \n",
       "12           26260.98       0  \n",
       "13          190857.79       0  \n",
       "14           65951.65       0  \n",
       "15           64327.26       0  \n",
       "16            5097.67       1  \n",
       "17           14406.41       0  \n",
       "18          158684.81       0  \n",
       "19           54724.03       0  \n",
       "20          170886.17       0  \n",
       "21          138555.46       0  \n",
       "22          118913.53       1  \n",
       "23            8487.75       0  \n",
       "24          187616.16       0  \n",
       "25          124508.29       0  \n",
       "26          170041.95       0  \n",
       "27           38433.35       0  \n",
       "28          100187.43       0  \n",
       "29           53483.21       0  \n",
       "...               ...     ...  \n",
       "9970        119377.36       0  \n",
       "9971        166472.81       0  \n",
       "9972        171552.02       0  \n",
       "9973        157474.10       0  \n",
       "9974         13549.24       0  \n",
       "9975        196526.55       1  \n",
       "9976         84419.78       0  \n",
       "9977         24991.92       0  \n",
       "9978        191608.97       0  \n",
       "9979          2988.28       0  \n",
       "9980         99595.67       0  \n",
       "9981         53445.17       1  \n",
       "9982        115146.40       1  \n",
       "9983        151325.24       0  \n",
       "9984         51695.41       0  \n",
       "9985         96833.00       0  \n",
       "9986         34047.54       0  \n",
       "9987          1914.41       0  \n",
       "9988         49337.84       0  \n",
       "9989        179436.60       0  \n",
       "9990         53667.08       0  \n",
       "9991         69384.71       1  \n",
       "9992        195192.40       0  \n",
       "9993         29179.52       0  \n",
       "9994        167773.55       0  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>2886.895680</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500.75</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>7.500250e+03</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>71936.186123</td>\n",
       "      <td>15565701.00</td>\n",
       "      <td>15628528.25</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>15815690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>6.505288e+02</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>350.00</td>\n",
       "      <td>584.00</td>\n",
       "      <td>6.520000e+02</td>\n",
       "      <td>7.180000e+02</td>\n",
       "      <td>850.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.892180e+01</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.012800e+00</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.648589e+04</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.719854e+04</td>\n",
       "      <td>1.276442e+05</td>\n",
       "      <td>250898.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.530200e+00</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.055000e-01</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.151000e-01</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.000902e+05</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.11</td>\n",
       "      <td>1.001939e+05</td>\n",
       "      <td>1.493882e+05</td>\n",
       "      <td>199992.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.037000e-01</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count          mean           std          min  \\\n",
       "RowNumber        10000.0  5.000500e+03   2886.895680         1.00   \n",
       "CustomerId       10000.0  1.569094e+07  71936.186123  15565701.00   \n",
       "CreditScore      10000.0  6.505288e+02     96.653299       350.00   \n",
       "Age              10000.0  3.892180e+01     10.487806        18.00   \n",
       "Tenure           10000.0  5.012800e+00      2.892174         0.00   \n",
       "Balance          10000.0  7.648589e+04  62397.405202         0.00   \n",
       "NumOfProducts    10000.0  1.530200e+00      0.581654         1.00   \n",
       "HasCrCard        10000.0  7.055000e-01      0.455840         0.00   \n",
       "IsActiveMember   10000.0  5.151000e-01      0.499797         0.00   \n",
       "EstimatedSalary  10000.0  1.000902e+05  57510.492818        11.58   \n",
       "Exited           10000.0  2.037000e-01      0.402769         0.00   \n",
       "\n",
       "                         25%           50%           75%          max  \n",
       "RowNumber            2500.75  5.000500e+03  7.500250e+03     10000.00  \n",
       "CustomerId       15628528.25  1.569074e+07  1.575323e+07  15815690.00  \n",
       "CreditScore           584.00  6.520000e+02  7.180000e+02       850.00  \n",
       "Age                    32.00  3.700000e+01  4.400000e+01        92.00  \n",
       "Tenure                  3.00  5.000000e+00  7.000000e+00        10.00  \n",
       "Balance                 0.00  9.719854e+04  1.276442e+05    250898.09  \n",
       "NumOfProducts           1.00  1.000000e+00  2.000000e+00         4.00  \n",
       "HasCrCard               0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "IsActiveMember          0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "EstimatedSalary     51002.11  1.001939e+05  1.493882e+05    199992.48  \n",
       "Exited                  0.00  0.000000e+00  0.000000e+00         1.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.head()\n",
    "df.tail()\n",
    "df.dtypes\n",
    "df.info\n",
    "df.isnull().values.any()\n",
    "df.isnull().sum().sum()\n",
    "df.isna().values.any()\n",
    "df.isna().sum().sum()\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Drop the columns which are unique for all users like IDs\n",
    "###Distinguish the feature and target set \n",
    "df_original = df.copy()\n",
    "x =  df.drop(['CustomerId','RowNumber','Surname','Exited'], axis=1)\n",
    "#y =  df.pop(\"Exited\")\n",
    "y = df[\"Exited\"]\n",
    "\n",
    "x.head()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 781.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null int8\n",
      "Gender             10000 non-null int8\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "dtypes: float64(2), int64(6), int8(2)\n",
      "memory usage: 644.6 KB\n"
     ]
    }
   ],
   "source": [
    "x.info()\n",
    "#pd.Categorical(x[\"Geography\"]).codes\n",
    "#pd.Categorical(x[\"Gender\"]).codes\n",
    "x[\"Geography\"] = pd.Categorical(x[\"Geography\"]).codes\n",
    "x[\"Gender\"] = pd.Categorical(df[\"Gender\"]).codes\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore         460\n",
       "Geography             3\n",
       "Gender                2\n",
       "Age                  70\n",
       "Tenure               11\n",
       "Balance            6382\n",
       "NumOfProducts         4\n",
       "HasCrCard             2\n",
       "IsActiveMember        2\n",
       "EstimatedSalary    9999\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.apply(lambda x: len(x.unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "###Divide the data set into Train and test sets\n",
    "\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 10) (7500,) (2500, 10) (2500,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 10) (7500,) (2500, 10) (2500,)\n",
      "(7500, 10) (2500, 10) (7500, 10) (2500, 10)\n"
     ]
    }
   ],
   "source": [
    "#Normalize the data\n",
    "#x_n = tf.nn.l2_normalize(x,1)\n",
    "\n",
    "#Option 1\n",
    "normalizer = Normalizer().fit(trainX)\n",
    "xtrainnorm = normalizer.transform(trainX) \n",
    "xtestnorm = normalizer.transform(testX) \n",
    "\n",
    "#Option 2\n",
    "sc=StandardScaler()\n",
    "xtrainstdsclr = sc.fit_transform(trainX)\n",
    "xteststdsclr = sc.transform(testX)\n",
    "\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "print(xtrainnorm.shape, xtestnorm.shape, xtrainstdsclr.shape, xteststdsclr.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Base Model\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 10),\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu'),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 106us/step - loss: 0.4945 - acc: 0.7976\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4310 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 0.4255 - acc: 0.7977\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4223 - acc: 0.8140\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.4197 - acc: 0.8261\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4180 - acc: 0.8285\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4169 - acc: 0.8299\n",
      "Epoch 8/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4158 - acc: 0.8319\n",
      "Epoch 9/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4149 - acc: 0.8324: 0s - loss: 0.4256 - a\n",
      "Epoch 10/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4142 - acc: 0.8340\n",
      "Epoch 11/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4130 - acc: 0.8344\n",
      "Epoch 12/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4132 - acc: 0.8325\n",
      "Epoch 13/25\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4122 - acc: 0.8345\n",
      "Epoch 14/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4115 - acc: 0.8347\n",
      "Epoch 15/25\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4113 - acc: 0.8351\n",
      "Epoch 16/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4110 - acc: 0.8352\n",
      "Epoch 17/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4108 - acc: 0.8341\n",
      "Epoch 18/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4102 - acc: 0.8340\n",
      "Epoch 19/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4100 - acc: 0.8352\n",
      "Epoch 20/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4093 - acc: 0.8356\n",
      "Epoch 21/25\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4089 - acc: 0.8352\n",
      "Epoch 22/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4087 - acc: 0.8365\n",
      "Epoch 23/25\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4081 - acc: 0.8349\n",
      "Epoch 24/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4079 - acc: 0.8351\n",
      "Epoch 25/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.4076 - acc: 0.8359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e31512f128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#model.fit(xtrainnorm, trainY, batch_size = 10, nb_epoch = 40)\n",
    "#score, acc = classifier.evaluate(xtestnorm, testY, verbose=0)\n",
    "#Later on - need to understand why acc is not improving with each epoch when xtrainnorm is used\n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25)\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.8332\n",
      "Accuracy(from confusion matrix) 0.8332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90      1980\n",
      "          1       0.74      0.31      0.44       520\n",
      "\n",
      "avg / total       0.82      0.83      0.81      2500\n",
      "\n",
      "[[1922   58]\n",
      " [ 359  161]]\n",
      "Area under the curve: = 0.64\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e3166edc50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,15,'predicted label')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'true label')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix plot with labels\n",
    "#sns.heatmap(cm.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=['No','Yes'], yticklabels=['No','Yes'] )\n",
    "sns.heatmap(cm, square=True, annot=True, fmt='d', cbar=False, xticklabels=['No','Yes'], yticklabels=['No','Yes'] )\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e3169c9828>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e3168caac8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'False positive rate')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'True positive rate')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'ROC curve')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e3169d3358>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Roc plot\n",
    "plt.plot([0, 1], [0, 1], 'k--',label='Random')\n",
    "plt.plot(fpr_ann,tpr_ann,label='ROC curve (area = %0.2f)' %roc_auc)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 0.4895 - acc: 0.7968\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4283 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4199 - acc: 0.7984\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.4104 - acc: 0.8268\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4011 - acc: 0.8284\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3930 - acc: 0.8312\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3861 - acc: 0.8413\n",
      "Epoch 8/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3819 - acc: 0.8455\n",
      "Epoch 9/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3781 - acc: 0.8463\n",
      "Epoch 10/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3758 - acc: 0.8456\n",
      "Epoch 11/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3758 - acc: 0.8488\n",
      "Epoch 12/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3734 - acc: 0.8501\n",
      "Epoch 13/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3716 - acc: 0.8525\n",
      "Epoch 14/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3711 - acc: 0.8512\n",
      "Epoch 15/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3702 - acc: 0.8484\n",
      "Epoch 16/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3697 - acc: 0.8508\n",
      "Epoch 17/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3676 - acc: 0.8513\n",
      "Epoch 18/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3673 - acc: 0.8517\n",
      "Epoch 19/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3677 - acc: 0.8528\n",
      "Epoch 20/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3649 - acc: 0.8536\n",
      "Epoch 21/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3648 - acc: 0.8517\n",
      "Epoch 22/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3650 - acc: 0.8544\n",
      "Epoch 23/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3645 - acc: 0.8528\n",
      "Epoch 24/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.3640 - acc: 0.8561\n",
      "Epoch 25/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3633 - acc: 0.8531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e318a44208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.8528\n",
      "Accuracy(from confusion matrix) 0.8528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91      1980\n",
      "          1       0.77      0.41      0.54       520\n",
      "\n",
      "avg / total       0.84      0.85      0.83      2500\n",
      "\n",
      "[[1917   63]\n",
      " [ 305  215]]\n",
      "Area under the curve: = 0.69\n"
     ]
    }
   ],
   "source": [
    "#Model tuning 1 - This has given the best accuracy. \n",
    "#Add additional hidden layer\n",
    "model = Sequential([\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 10),\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu'),\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu'),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25)\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n",
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=8, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=12, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 125us/step - loss: 0.4749 - acc: 0.7973\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4282 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4215 - acc: 0.8209\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.4183 - acc: 0.8280\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4161 - acc: 0.8308\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.4140 - acc: 0.8312\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4127 - acc: 0.8329\n",
      "Epoch 8/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.4114 - acc: 0.8337\n",
      "Epoch 9/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.4099 - acc: 0.8336\n",
      "Epoch 10/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4089 - acc: 0.8335\n",
      "Epoch 11/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4083 - acc: 0.8329\n",
      "Epoch 12/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.4081 - acc: 0.8347\n",
      "Epoch 13/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4072 - acc: 0.8353\n",
      "Epoch 14/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4067 - acc: 0.8356\n",
      "Epoch 15/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4061 - acc: 0.8352\n",
      "Epoch 16/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4062 - acc: 0.8333\n",
      "Epoch 17/25\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.4057 - acc: 0.8367\n",
      "Epoch 18/25\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.4045 - acc: 0.8335\n",
      "Epoch 19/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.4051 - acc: 0.8347\n",
      "Epoch 20/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.4041 - acc: 0.8347\n",
      "Epoch 21/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4044 - acc: 0.8343\n",
      "Epoch 22/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4043 - acc: 0.8355\n",
      "Epoch 23/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4031 - acc: 0.8325\n",
      "Epoch 24/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4038 - acc: 0.8348\n",
      "Epoch 25/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.4028 - acc: 0.8360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e318f74630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.8364\n",
      "Accuracy(from confusion matrix) 0.8364\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90      1980\n",
      "          1       0.77      0.31      0.44       520\n",
      "\n",
      "avg / total       0.83      0.84      0.81      2500\n",
      "\n",
      "[[1932   48]\n",
      " [ 361  159]]\n",
      "Area under the curve: = 0.64\n"
     ]
    }
   ],
   "source": [
    "#Model tuning 2\n",
    "#Add more neurons\n",
    "model = Sequential([\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 10),\n",
    " Dense(output_dim = 12, init = 'uniform', activation = 'relu'),\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu'),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25)\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n",
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, kernel_regularizer=<keras.reg..., units=8, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=12, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=8, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 138us/step - loss: 0.4768 - acc: 0.7977\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4307 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4245 - acc: 0.8104\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4208 - acc: 0.8263\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4184 - acc: 0.8296\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4171 - acc: 0.8291\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4154 - acc: 0.8332\n",
      "Epoch 8/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4136 - acc: 0.8320\n",
      "Epoch 9/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4124 - acc: 0.8333\n",
      "Epoch 10/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4112 - acc: 0.8316\n",
      "Epoch 11/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4104 - acc: 0.8333\n",
      "Epoch 12/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4099 - acc: 0.8340\n",
      "Epoch 13/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4092 - acc: 0.8351\n",
      "Epoch 14/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4077 - acc: 0.8351\n",
      "Epoch 15/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4073 - acc: 0.8335\n",
      "Epoch 16/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4074 - acc: 0.8341\n",
      "Epoch 17/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4058 - acc: 0.8353\n",
      "Epoch 18/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4067 - acc: 0.8332\n",
      "Epoch 19/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4062 - acc: 0.8343\n",
      "Epoch 20/25\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4057 - acc: 0.8339\n",
      "Epoch 21/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4049 - acc: 0.8340\n",
      "Epoch 22/25\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.4045 - acc: 0.8323\n",
      "Epoch 23/25\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.4050 - acc: 0.8324\n",
      "Epoch 24/25\n",
      "7500/7500 [==============================] - 1s 93us/step - loss: 0.4048 - acc: 0.8327\n",
      "Epoch 25/25\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.4047 - acc: 0.8340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e31a48a5f8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.8364\n",
      "Accuracy(from confusion matrix) 0.8364\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90      1980\n",
      "          1       0.75      0.32      0.45       520\n",
      "\n",
      "avg / total       0.83      0.84      0.81      2500\n",
      "\n",
      "[[1926   54]\n",
      " [ 355  165]]\n",
      "Area under the curve: = 0.65\n"
     ]
    }
   ],
   "source": [
    "#Model tuning 3\n",
    "#use L2 regularizers\n",
    "model = Sequential([\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 10, kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim = 12, init = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25)\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n",
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, kernel_regularizer=<keras.reg..., units=8, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=12, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=8, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 145us/step - loss: 0.4980 - acc: 0.7976\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4370 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4355 - acc: 0.7977\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4346 - acc: 0.7977\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4345 - acc: 0.7977\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.4329 - acc: 0.7977\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.4278 - acc: 0.8029\n",
      "Epoch 8/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4237 - acc: 0.8207\n",
      "Epoch 9/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4217 - acc: 0.8288\n",
      "Epoch 10/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4200 - acc: 0.8309\n",
      "Epoch 11/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4183 - acc: 0.8299\n",
      "Epoch 12/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4180 - acc: 0.8325\n",
      "Epoch 13/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4168 - acc: 0.8323\n",
      "Epoch 14/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4161 - acc: 0.8329\n",
      "Epoch 15/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4157 - acc: 0.8332\n",
      "Epoch 16/25\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.4154 - acc: 0.8339\n",
      "Epoch 17/25\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.4145 - acc: 0.8340\n",
      "Epoch 18/25\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4141 - acc: 0.8340\n",
      "Epoch 19/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.4135 - acc: 0.8340\n",
      "Epoch 20/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4128 - acc: 0.8347\n",
      "Epoch 21/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.4127 - acc: 0.8343\n",
      "Epoch 22/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4125 - acc: 0.8347\n",
      "Epoch 23/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.4120 - acc: 0.8351\n",
      "Epoch 24/25\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.4123 - acc: 0.8363\n",
      "Epoch 25/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.4114 - acc: 0.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e31ba6f588>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.8332\n",
      "Accuracy(from confusion matrix) 0.8332\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.90      1980\n",
      "          1       0.72      0.33      0.45       520\n",
      "\n",
      "avg / total       0.82      0.83      0.81      2500\n",
      "\n",
      "[[1914   66]\n",
      " [ 351  169]]\n",
      "Area under the curve: = 0.65\n"
     ]
    }
   ],
   "source": [
    "#Model tuning 4\n",
    "#use L1 regularizers\n",
    "model = Sequential([\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 10, kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim = 12, init = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25)\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n",
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=8, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=12, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 0.4865 - acc: 0.7977\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4467 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4418 - acc: 0.7977\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4422 - acc: 0.7977\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4394 - acc: 0.7977\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4415 - acc: 0.7977\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 93us/step - loss: 0.4367 - acc: 0.7977\n",
      "Epoch 8/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4383 - acc: 0.7977\n",
      "Epoch 9/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4375 - acc: 0.7977\n",
      "Epoch 10/25\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.4327 - acc: 0.7977\n",
      "Epoch 11/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4347 - acc: 0.7977\n",
      "Epoch 12/25\n",
      "7500/7500 [==============================] - 1s 96us/step - loss: 0.4401 - acc: 0.7977\n",
      "Epoch 13/25\n",
      "7500/7500 [==============================] - 1s 99us/step - loss: 0.4336 - acc: 0.7977\n",
      "Epoch 14/25\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.4392 - acc: 0.7977\n",
      "Epoch 15/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4356 - acc: 0.7977\n",
      "Epoch 16/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4344 - acc: 0.7977\n",
      "Epoch 17/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4335 - acc: 0.7977\n",
      "Epoch 18/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4311 - acc: 0.7977\n",
      "Epoch 19/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4363 - acc: 0.7977\n",
      "Epoch 20/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4364 - acc: 0.7977\n",
      "Epoch 21/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4339 - acc: 0.7977\n",
      "Epoch 22/25\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.4333 - acc: 0.7977\n",
      "Epoch 23/25\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 0.4337 - acc: 0.7977\n",
      "Epoch 24/25\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.4368 - acc: 0.7977\n",
      "Epoch 25/25\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.4341 - acc: 0.7977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e31d0166d8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.792\n",
      "Accuracy(from confusion matrix) 0.792\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88      1980\n",
      "          1       0.00      0.00      0.00       520\n",
      "\n",
      "avg / total       0.63      0.79      0.70      2500\n",
      "\n",
      "[[1980    0]\n",
      " [ 520    0]]\n",
      "Area under the curve: = 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Model tuning 5\n",
    "#Add Dropout layers\n",
    "from keras.layers.core import Dropout\n",
    "model = Sequential([\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 10),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim = 12, init = 'uniform', activation = 'relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25)\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n",
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=8, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=12, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 0.4878 - acc: 0.7977\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.4445 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4450 - acc: 0.7977\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 93us/step - loss: 0.4354 - acc: 0.7977\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4395 - acc: 0.7977\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 103us/step - loss: 0.4378 - acc: 0.7977\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 105us/step - loss: 0.4352 - acc: 0.7977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e31e74ed68>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.792\n",
      "Accuracy(from confusion matrix) 0.792\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88      1980\n",
      "          1       0.00      0.00      0.00       520\n",
      "\n",
      "avg / total       0.63      0.79      0.70      2500\n",
      "\n",
      "[[1980    0]\n",
      " [ 520    0]]\n",
      "Area under the curve: = 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Model tuning 6\n",
    "#Use Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "model = Sequential([\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 10),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim = 12, init = 'uniform', activation = 'relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim = 8, init = 'uniform', activation = 'relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25, callbacks = [EarlyStopping(monitor='acc', patience=4)])\n",
    "\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n",
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7500/7500 [==============================] - 1s 163us/step - loss: 0.6637 - acc: 0.7971\n",
      "Epoch 2/25\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.6174 - acc: 0.7977\n",
      "Epoch 3/25\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.5853 - acc: 0.7977\n",
      "Epoch 4/25\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.5629 - acc: 0.7977\n",
      "Epoch 5/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.5470 - acc: 0.7977\n",
      "Epoch 6/25\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.5356 - acc: 0.7977\n",
      "Epoch 7/25\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.5274 - acc: 0.7977\n",
      "Epoch 8/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.5214 - acc: 0.7977\n",
      "Epoch 9/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.5170 - acc: 0.7977\n",
      "Epoch 10/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.5137 - acc: 0.7977\n",
      "Epoch 11/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.5113 - acc: 0.7977\n",
      "Epoch 12/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.5095 - acc: 0.7977\n",
      "Epoch 13/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.5081 - acc: 0.7977\n",
      "Epoch 14/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.5070 - acc: 0.7977\n",
      "Epoch 15/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.5062 - acc: 0.7977\n",
      "Epoch 16/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.5056 - acc: 0.7977\n",
      "Epoch 17/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.5051 - acc: 0.7977\n",
      "Epoch 18/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.5048 - acc: 0.7977\n",
      "Epoch 19/25\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.5045 - acc: 0.7977\n",
      "Epoch 20/25\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.5043 - acc: 0.7977\n",
      "Epoch 21/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.5041 - acc: 0.7977\n",
      "Epoch 22/25\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.5040 - acc: 0.7977\n",
      "Epoch 23/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.5039 - acc: 0.7977\n",
      "Epoch 24/25\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.5038 - acc: 0.7977\n",
      "Epoch 25/25\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.5037 - acc: 0.7977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e325232be0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy( from evaluate): 0.792\n",
      "Accuracy(from confusion matrix) 0.792\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      1.00      0.88      1980\n",
      "          1       0.00      0.00      0.00       520\n",
      "\n",
      "avg / total       0.63      0.79      0.70      2500\n",
      "\n",
      "[[1980    0]\n",
      " [ 520    0]]\n",
      "Area under the curve: = 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Model tuning 7 \n",
    "#Use SGD optimizer\n",
    "\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.001)\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 10),\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu'),\n",
    " Dense(output_dim = 6, init = 'uniform', activation = 'relu'),\n",
    " Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
    "\n",
    "model.fit(xtrainstdsclr, trainY, batch_size = 10, nb_epoch = 25)\n",
    "score, acc = model.evaluate(xteststdsclr, testY, verbose=0)\n",
    "\n",
    "y_pred_prob = model.predict(xteststdsclr)\n",
    "#print(y_pred_prob)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype('int')\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, y_pred)\n",
    "\n",
    "#testY.value_counts()\n",
    "#pd.Series(y_pred.tolist()).value_counts()\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "print('Test accuracy( from evaluate):', acc)\n",
    "print(\"Accuracy(from confusion matrix)\", accuracy(cm))\n",
    "\n",
    "#Print Classification Report\n",
    "print(classification_report(testY, y_pred))\n",
    "\n",
    "#Confusion matrix\n",
    "print(cm)\n",
    "\n",
    "#ROC - Area under the curve\n",
    "fpr_ann,tpr_ann,_ann=roc_curve(testY, y_pred)\n",
    "roc_auc=auc(fpr_ann,tpr_ann)\n",
    "print(\"Area under the curve: = %0.2f\"%roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
